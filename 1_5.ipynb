{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP0T4Ypw8Ghy8ZhCorDmu4j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rk76977/MAT-422/blob/main/1_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2.2.1. Probability axioms**"
      ],
      "metadata": {
        "id": "V_iNQC-2KTq1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sorry, I did not include anything for probability axioms."
      ],
      "metadata": {
        "id": "pR2JxCQ4AsJJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2.2.2. Conditional probability**"
      ],
      "metadata": {
        "id": "mGGu6Nh2jzvo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### An idea I learned is that mutual independence is stronger than pairwise independence"
      ],
      "metadata": {
        "id": "79BtUCt4p0vC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "An example is, suppose we flip two coins. let $A$ be the event that the first coin is heads, $B$ be the event that the second is heads, and $C$ be the event that the coins land on the same value. Since knowing if the first coin is heads does not change $P(C)$, $C$ is independent of $A$ and similarly is independent of $B$.\n",
        "\n",
        "But if both coins are heads, then they have the same value, so $(P(C) | A\\cap B)=1$, whereas if the coins aren't both heads, they don't necessarily have be the same value, so $(P(C) | A \\cap B )< 1$. So $C$ and $A \\cap B$ are not independent, so $A,B,C$ are pairwise independent but are not mutually independent."
      ],
      "metadata": {
        "id": "4gLFg-B6kMd6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2.2.3. Discrete random variables**"
      ],
      "metadata": {
        "id": "-o3KDbYWpZoA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One cool idea is that, for two discrete random variables $X$ and $Y$, we can find $E(X+Y)$ even if they're independent. If we let $p_i$ be the probability of observing $x_i$ and let $q_{j|i}$ be the probability of observing $y_j$ given $x_i$, then we can write $E[X+Y]$ as\n",
        "$$\\sum\\limits_{i,j}^{} (x+y)p(i)q(j|i)$$,\n",
        "which can be written as\n",
        "$$\\sum\\limits_{i}^{}\\sum\\limits_{j}^{} x_i \\cdot p(i)q(j|i) + \\sum\\limits_{j}^{}\\sum\\limits_{i}^{} y_j \\cdot p(i)q(j|i)$$\n",
        "Since $\\sum\\limits_{j}^{}q(j|i)=1$, the first sum is\n",
        "$$\\sum\\limits_{i}^{} x_i \\cdot p(i)=E[x]$$\n",
        "Similarly, if we also treat $Y$ as an isolated distribution with the probability of observing $y_j$ being $q'(j)$, then\n",
        "$$\\sum\\limits_{i}^{}p(i)q(j|i)=1$$\n",
        ", so the second sum is\n",
        "$$\\sum\\limits_{j}^{}y_j \\cdot q'(j) = E[Y]$$\n",
        "\n"
      ],
      "metadata": {
        "id": "5gUW7zIEtmvF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Illustrating linearity of expectation"
      ],
      "metadata": {
        "id": "yOXmyIWFpv_n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that, if we have a list of infinite discrete random variables $X_1 \\dots $, and $E[X_1] + \\dots $ converges, then $E[X_1 \\dots ] = E[X_1] + \\dots $, even if all the $X_i$ are dependent!"
      ],
      "metadata": {
        "id": "DFlcAu6XxLyP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So suppose we're playing in an infinite lottery game. We start at stage 1 where there are 2 doors, one leading to the next stage, where we get a dollar, and one that ends the game. At each next stage, there are twice as many doors as the previous stage, and only the last door number leads to the next stage and gives us a dollar, and all other doors end the game.\n",
        "\n",
        "So our number of doors is $2,4, 8 \\dots$, and if we let $X_i$ be the event that we get a dollar on the $i$th stage, then $E[X_i] = \\frac{1}{2^{i+1}}$, so if $X$ is our total number of dollars once the game ends, $E[x]=\\sum\\limits_{j}^{} \\frac{1}{2^{i+1}}=1$, so we'd expect to get 1 full dollar!\n",
        "\n",
        "So let's simulate this."
      ],
      "metadata": {
        "id": "KhzcxH_gqCRm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Simulating the game"
      ],
      "metadata": {
        "id": "ryePqJFqywpJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "HuwD4TvYAGk-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "def game():\n",
        "  numdollars=0\n",
        "  stage=1\n",
        "  still_playing=True\n",
        "  while(still_playing):\n",
        "    numdoors = int(2**(stage))\n",
        "    doorchoice=random.randint(1,numdoors)\n",
        "    if doorchoice==1:\n",
        "      numdollars+=1\n",
        "      stage+=1\n",
        "    else:\n",
        "      still_playing=False\n",
        "  return numdollars\n",
        "\n",
        "totaldollars=0\n",
        "numgames=100000\n",
        "for i in range(numgames):\n",
        "  totaldollars+=game()\n",
        "meandollars=totaldollars/numgames\n",
        "print(\"Mean dollars from {} game simulations: {}\".format(numgames,meandollars))\n",
        "\n"
      ],
      "metadata": {
        "id": "DpqFisP5y8LF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Highly interestingly, the mean is around .641. This actually made me very confused. I might be off, but I think my analysis is correct that you can prove the expected value converges to 1. I think this python loops might be terminating too early or that the estimate is low. Hopefully I am not incorrect. I might try to revisit this in the future if possible. Sorry."
      ],
      "metadata": {
        "id": "VqHMuyFQ-npo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2.2.4. Continues random variables**"
      ],
      "metadata": {
        "id": "zasgSuWhANia"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I didn't add anything extra for this section since I think the previous was also similar to this section, sorry."
      ],
      "metadata": {
        "id": "35g5ceQDAP3J"
      }
    }
  ]
}