{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMuzpyLG+YU94Mzw5vOGD/t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rk76977/MAT-422/blob/main/3_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3.3.1. Necessary and sufficient conditions of local minimizers**"
      ],
      "metadata": {
        "id": "SCqEqA2m0-qW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A local minimizer $x_0$ of a function $f : \\mathbb{R}^n â†’ \\mathbb{R}$ is a point that is a minimum within a ball centered at $x_0$.\n",
        "\n",
        "A sufficient condition for being a strict local minimizer is when $H$, the hessian matrix for $f$ at $x_0$, is positive semidefinite the gradient of $f$ at $x_0$ is $0$."
      ],
      "metadata": {
        "id": "tJ_o5N-GNtmp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use this to find the minimum of the function $f(x,y)=x^2+xy+y^2+1$. Note that the hessian matrix is $\\begin{bmatrix}\n",
        "  2 & 1 \\\\\n",
        "  1 & 2\n",
        "\\end{bmatrix}$ for all $(x,y)$ and the gradient is $\\begin{bmatrix}\n",
        "  2x+y  \\\\\n",
        "  2y+x\n",
        "\\end{bmatrix}$. Thus, setting $2x+y=2y+x=0$ gives $x=y=0$, and the hessian is semi positive definite because the the principal submatrix determinants are positive, so $(0,0$ is a strict local minimizer of $f$."
      ],
      "metadata": {
        "id": "emO5-QTTdPAm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code to illustrate this is"
      ],
      "metadata": {
        "id": "31_tCveAeSwo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def f(x,y):\n",
        "  return x*x+x*y+y*y+1\n",
        "\n",
        "for i in range(2):\n",
        "  for j in range(2):\n",
        "    x,y = np.random.uniform(-1, 1),np.random.uniform(-1, 1)\n",
        "    if(f(x,y) >= f(0,0)):\n",
        "      print(\"f(x,y) >= f(0,0)\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwzFyuQReX04",
        "outputId": "4b5e5364-95a8-4eb5-c5db-36fb6db095d2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f(x,y) >= f(0,0)\n",
            "f(x,y) >= f(0,0)\n",
            "f(x,y) >= f(0,0)\n",
            "f(x,y) >= f(0,0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3.3.2. Convexity and global minimizers**"
      ],
      "metadata": {
        "id": "B6FOmxoDRJsK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A convex function is a function that, for any $x,y$ in the domain, the line between $f(x),f(y)$ is in the range."
      ],
      "metadata": {
        "id": "Z_k3SO4gS-sq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Considering $f = 1-x^2$, note that if we have $1-x^2$, $1-y^2$, then $a(1-x^2 - (1-y^2)) + 1-x^2 = 1 -(x^2(1-a) +ay^2)$, and since $a$ is between 0 and 1, the term in parenthesis is nonnegative, and hence $1-x^2 = 1 -(x^2(1-a) +ay^2)$ is in the range, so $1-x^2$ is convex"
      ],
      "metadata": {
        "id": "Px_NHxvLi1Ig"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3.3.3. Gradient descent**"
      ],
      "metadata": {
        "id": "OVj--qjC3P6U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example of gradient descent for finding the minimum of $x^2$"
      ],
      "metadata": {
        "id": "HEvcAZ4X4OgS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def derivative_of_x_squared(x):\n",
        "  return 2*x\n",
        "\n",
        "l = .01\n",
        "\n",
        "x = np.random.uniform(-10, 10)\n",
        "\n",
        "for i in range(1000):\n",
        "  x = x - derivative_of_x_squared(x)*l\n",
        "\n",
        "print(x)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Bt3JS98k8Tm",
        "outputId": "93de9486-f30a-4a27-d02f-3bc390573d91"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-1.5958330606885474e-08\n"
          ]
        }
      ]
    }
  ]
}